# Master Research Synthesis: AI Workflow Specification Landscape
**Compiled**: January 2026  
**Scope**: Systematic analysis of 150+ projects, deep-dives on 10+ frameworks, comparative analysis including internal experiments

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Research Methodology](#research-methodology)
3. [Market Landscape Overview](#market-landscape-overview)
4. [Framework Deep Dives](#framework-deep-dives)
5. [Internal Experiment: Spec_Engine](#internal-experiment-spec_engine)
6. [Comparative Analysis](#comparative-analysis)
7. [Pattern Catalogue](#pattern-catalogue)
8. [Gap Analysis & Recommendations](#gap-analysis--recommendations)
9. [Strategic Positioning](#strategic-positioning)
10. [Implementation Roadmap](#implementation-roadmap)

---

## Executive Summary

### Five Paradigm Shifts Reshaping the Market

| Shift | Evidence | Implication |
|-------|----------|-------------|
| **SDD is mainstream** | 100k+ combined stars across top 6 tools | Table stakes, not differentiator |
| **Brownfield > Greenfield** | OpenSpec (14.8k stars) explicitly "brownfield-first" | Most value in existing codebases |
| **Dashboards expected** | Every major framework has visual tracking | CLI-only increasingly insufficient |
| **Constitution-first universal** | Spec Kit, Vibe Check, OpenSpec all mandate it | Standards before execution |
| **MCP is the glue** | 50+ MCP servers, 35k+ combined stars | Universal integration layer |

### The Understanding Gap

```
                    SPEED
            â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
            Fast              Slow
            
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   D   â”‚  Spec Kit    â”‚            â”‚  High
   E   â”‚  OpenSpec    â”‚   Lia?     â”‚
   P   â”‚  cc-sdd      â”‚            â”‚
   T   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   H   â”‚  Task Master â”‚            â”‚  Low
       â”‚              â”‚            â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

OPPORTUNITY: "Slow + Deep" quadrant is underserved
```

---

## Research Methodology

### Systematic Reconnaissance Approach

**Dimensions Scanned** (10 total):
1. GitHub trending + high-star repos
2. MCP server ecosystem
3. Academic/enterprise implementations
4. CLI tools and frameworks
5. IDE integrations (Cursor, Windsurf, Claude Code)
6. Workflow orchestration platforms
7. Prompt engineering/management tools
8. Documentation generators
9. Security-focused tools
10. Multi-agent systems

**Methodology**:
- GitHub API queries across multiple search terms
- Documentation deep-dives (40+ pages analysed)
- Pattern extraction and categorisation
- Comparative matrix building
- Internal experimentation (Spec_Engine)

---

## Market Landscape Overview

### Tier Classification

| Tier | Definition | Examples | Stars |
|------|------------|----------|-------|
| **Tier 0** | Industry standards | GitHub Spec Kit | 59k+ |
| **Tier 1** | Major frameworks | Claude-Flow, APM, OpenSpec | 10k-15k |
| **Tier 2** | Established tools | Vibe Check, CodeGuard, cc-sdd | 400-1.6k |
| **Tier 3** | Emerging/Niche | Spec Kitty, Clavix, Liatrio SDD | 50-300 |
| **Experimental** | Internal projects | Spec_Engine | New |

### Key Players Matrix

| Framework | Focus | Unique Strength | Weakness |
|-----------|-------|-----------------|----------|
| **Spec Kit** | Autonomous execution | Constitution + 5-command flow | Overkill for simple tasks |
| **OpenSpec** | Brownfield support | Change tracking, proposals | Complex setup |
| **Claude-Flow** | Multi-agent | Hive-mind architecture | Enterprise-heavy |
| **Vibe Check** | Agent oversight | +27% success rate research | Limited scope |
| **APM** | Context retention | 10+ tool support | Jack of all trades |
| **Spec_Engine** | Constitutional governance | 14 Articles, 3-file architecture | Complexity overhead |
| **Lia Specs** | Educational transparency | Tool-agnostic, simple TOML | Missing some patterns |

---

## Framework Deep Dives

### 1. GitHub Spec Kit (59k+ stars)

**Core Philosophy**: "The Power Inversion"
> "Specifications don't serve codeâ€”code serves specifications."

**Architecture**:
```
Constitution â†’ Specify â†’ Plan â†’ Tasks â†’ Implement
     â†“            â†“         â†“        â†“          â†“
  Project     WHAT to    HOW to   Actionable  Execute
  Standards   build      build    breakdown   + verify
```

**Key Patterns**:
- **Constitution is mandatory first step** (Article VII: Simplicity Gate, Article VIII: Anti-Abstraction Gate)
- **Template-driven quality** - Prevents premature implementation
- **User stories as MVP slices** - Independently testable/deployable
- **Uncertainty markers** - `[NEEDS CLARIFICATION: specific question]`

**Lesson**: Rigorous governance produces consistent results.

---

### 2. Vibe Check MCP (440+ stars)

**Core Philosophy**: Pattern Inertia Prevention
> "LLMs can confidently follow flawed plans. Without an external nudge they may spiral into overengineering."

**Research Results**:
- +27% success rate with Vibe Check
- -41% harmful actions
- Optimal interrupt dosage: 10-20% of steps

**Key Innovation**: Chain-Pattern Interrupt (CPI)
```
Agent Phase â†’ Monitor Progress â†’ [high risk?] â†’ CPI Interrupt â†’ Reflect & Adjust
                                 [smooth?]    â†’ Continue
```

**Tools Provided**:
| Tool | Purpose |
|------|---------|
| `vibe_check` | Challenge assumptions |
| `vibe_learn` | Capture mistakes for learning |
| `update_constitution` | Set session rules |
| `check_constitution` | Inspect effective rules |

**Lesson**: Structured interrupts significantly improve outcomes.

---

### 3. Liatrio Spec-Driven Workflow (49 stars)

**Core Innovation**: Evidence-Driven Development

**Context Verification Markers**:
Each phase starts with markers (SDD1ï¸âƒ£, SDD2ï¸âƒ£):
> "If marker disappears, context has been lost."

**Proof Artifacts Pattern**:
```
docs/specs/[NN]-spec-[feature-name]/
â”œâ”€â”€ [NN]-spec-[feature-name].md
â”œâ”€â”€ [NN]-tasks-[feature-name].md
â”œâ”€â”€ [NN]-proofs/
â”‚   â”œâ”€â”€ [NN]-task-01-proofs.md
â”‚   â””â”€â”€ [NN]-task-02-proofs.md
â””â”€â”€ [NN]-validation-[feature-name].md
```

**Lesson**: Proof before commit creates accountability.

---

### 4. OpenSpec (14.8k stars)

**Core Philosophy**: Brownfield-First
> "Works great beyond 0â†’1"

**Change Tracking Pattern**:
```
Current Truth (specs/)  â†’  Proposed Changes (changes/)  â†’  Archive & Merge
```

**Key Innovation**: Spec Deltas
- Clear diff between current and proposed
- Audit trail of decisions
- Clean merge when approved

**Lesson**: Most value is in existing codebases; design for change.

---

## Internal Experiment: Spec_Engine

### Overview

**Repository**: github.com/earlyprototype/Spec_Engine  
**Description**: "A constitutional framework for autonomous LLM development"  
**Status**: Active experiment

### Architecture

```
Constitution (14 Articles)
    â”‚
    â–¼
Commander (generates specs from goals)
    â”‚
    â–¼
Three-File Architecture:
â”œâ”€â”€ spec_[name].md       (Human intent)
â”œâ”€â”€ parameters_[name].toml (Machine config)
â””â”€â”€ exe_[name].md        (Execution controller)
    â”‚
    â–¼
Progress Tracking (progress_[name].json)
```

### Key Innovations

| Feature | Description | Unique? |
|---------|-------------|---------|
| **14-Article Constitution** | Immutable governance (Article I: North Star, Article VI: Critical Flag Discipline) | âœ… Most rigorous |
| **Dual-file bridging** | Markdown for humans, TOML for machines, explicit sync requirements | âœ… Unusual |
| **SPEClet abstraction** | Work packages with dependency graphs for complex goals | âœ… Novel |
| **Error propagation strategies** | `halt_on_critical`, `continue_and_log`, `collaborative_review` | âš ï¸ Similar to others |
| **Backup philosophy** | "Alternative reasoning paths, NOT simple retries" | âœ… Underemphasised elsewhere |
| **Criticality balance** | "40-60% of steps should be critical" | âœ… Quantified guidance |
| **DNA codes** | 8-character project identifiers | âš ï¸ Nice-to-have |
| **MCP tools integration** | First-class required/recommended/optional tiers | âš ï¸ Emerging pattern |
| **Pre-flight validation** | 10-step validation before ANY execution | âœ… Thorough |

### Weakness Analysis (Post-Mortem)

**Source**: `TGACGTCA_weakness_summary_20260102.md`

| Weakness | Description | Severity |
|----------|-------------|----------|
| **Troubleshooting Cliff** | 100% success during creation, systemic failure during debugging. No structured troubleshooting framework. | ğŸ”´ Critical |
| **Deceptive Status Reporting** | "Fixed" claimed without verification. Status based on intent, not outcome. | ğŸ”´ Critical |
| **Production Configuration Blind Spots** | Features implemented but "glue" configuration missed (next.config.ts, SSR patterns). | ğŸŸ¡ High |
| **Rigid Governance** | 40-60% critical guideline creates false positives for production deployments (70% may be appropriate). | ğŸŸ¡ High |

### Key Insight: The "Troubleshooting Cliff"

```
CREATION PHASE                    TROUBLESHOOTING PHASE
     â”‚                                    â”‚
     â–¼                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 100% Successâ”‚                    â”‚  20+ Errors â”‚
â”‚ 0 errors    â”‚                    â”‚  Circular   â”‚
â”‚ Structured  â”‚                    â”‚  Ad-hoc     â”‚
â”‚ Governed    â”‚                    â”‚  Ungoverned â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                                   â†“
   SHARP CLIFF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**Root Cause**: Once the Execution Controller finishes, agents fall back to unstructured debugging with context degradation, loss of prior attempts, and user frustration.

**Recommendation**: Need structured troubleshooting spec (`troubleshoot.toml` exists in Lia, but Spec_Engine lacks equivalent).

---

## Comparative Analysis

### Feature Matrix

| Feature | Spec Kit | OpenSpec | Vibe Check | Spec_Engine | Lia |
|---------|----------|----------|------------|-------------|-----|
| Constitution | âœ… Mandatory | âœ… Project-level | âœ… Session-level | âœ… 14 Articles | âœ… constitution.toml |
| Scope Guard | âš ï¸ Implicit | âŒ | âœ… CPI Interrupt | âš ï¸ Via Constitution | âœ… Explicit pattern |
| Self-Correction | âœ… | âœ… | âœ… | âœ… Max 3 retries | âœ… Max 3 retries |
| Proof Artifacts | âš ï¸ Implicit | âŒ | âŒ | âŒ | âœ… dev.toml Phase 7 |
| Context Markers | âŒ | âŒ | âŒ | âŒ | âœ… LIA-DEV-1ï¸âƒ£ |
| Brownfield Support | âš ï¸ Limited | âœ… Core focus | âŒ | âŒ | âœ… spec.toml |
| Error Propagation | âš ï¸ | âš ï¸ | âŒ | âœ… 3 strategies | âš ï¸ Abort only |
| Backup Philosophy | âŒ | âŒ | âŒ | âœ… "Alternative reasoning" | âŒ |
| Criticality Guidance | âŒ | âŒ | âŒ | âœ… "40-60%" | âŒ |
| Troubleshooting Framework | âš ï¸ | âŒ | âŒ | âŒ (Gap) | âœ… troubleshoot.toml |
| Verification Before Status | âš ï¸ | âŒ | âœ… | âŒ (Gap) | âš ï¸ |
| Three-File Architecture | âŒ 4-file | âŒ | âŒ | âœ… | âŒ Single TOML |
| MCP Integration | âŒ | âŒ | âœ… | âœ… First-class | âœ… Server exists |
| Tool Agnostic | âš ï¸ | âš ï¸ | âœ… | âš ï¸ | âœ… Core strength |

### Philosophy Comparison

| Dimension | Spec Kit | Spec_Engine | Lia |
|-----------|----------|-------------|-----|
| **Primary Goal** | Autonomous execution | Constitutional governance | Educational transparency |
| **Speed vs Depth** | Fast | Medium | Slow/Deep |
| **Complexity** | Medium | High | Low |
| **Learning Curve** | Moderate | Steep | Gentle |
| **Target User** | Experienced devs | Power users | All developers |
| **Governance Model** | Implicit in templates | Explicit 14 Articles | Lightweight constitution |

---

## Pattern Catalogue

### Patterns Adopted by Lia

| Pattern | Source | Implementation | Status |
|---------|--------|----------------|--------|
| Constitutional Governance | Spec Kit, Spec_Engine | `constitution.toml` | âœ… Done |
| Scope Guard Checkpoints | Vibe Check | `base-workflow.toml`, `dev.toml` | âœ… Done |
| Self-Correction Loop | Industry standard | `base-workflow.toml` | âœ… Done |
| Confidence Signals | OpenAgents | `base-workflow.toml` | âœ… Done |
| Abort Conditions | Industry standard | `base-workflow.toml` | âœ… Done |
| Context Rot Detection | Liatrio SDD | `dev.toml`, `spec.toml` markers | âœ… Done |
| Proof Artifacts | Liatrio SDD | `dev.toml` Phase 7 | âœ… Done |
| Brownfield Support | OpenSpec | `spec.toml` existing system analysis | âœ… Done |
| Recon Methodology | Internal research | `recon.toml` | âœ… Done |

### Patterns To Adopt from Spec_Engine

| Pattern | Description | Priority | Effort |
|---------|-------------|----------|--------|
| **Backup as Alternative Reasoning** | "Alternative reasoning paths, NOT simple retries" | P1 | 3h |
| **Error Propagation Strategies** | `halt_on_critical`, `continue_and_log`, `collaborative_review` | P1 | 4h |
| **Criticality Balance Guidance** | "40-60% of steps should be critical" | P1 | 1h |
| **Pre-flight Validation** | Structured 10-step validation before execution | P2 | 6h |
| **Verification Before Status** | Mandate proof that fixes work before claiming "Fixed" | P1 | 2h |

### Patterns To Avoid

| Pattern | Source | Why Avoid |
|---------|--------|-----------|
| Three-File Architecture | Spec_Engine | Adds complexity; single source of truth preferred |
| Manual File Sync | Spec_Engine | Error-prone; prefer auto-generation |
| Rigid Criticality Thresholds | Spec_Engine | Context-dependent; should be guidelines not rules |

---

## Gap Analysis & Recommendations

### Critical Gaps Identified

#### Gap 1: Alternative Reasoning Backups
**Current State**: No explicit guidance on what constitutes a valid backup approach  
**Market Standard**: Spec_Engine's "alternative reasoning paths, NOT simple retries"  
**Recommendation**: Add to `base-workflow.toml`

```markdown
### Backup Method Philosophy

Valid backups are **alternative reasoning paths**:
- âœ… "If documentation incomplete, inspect source code directly"
- âœ… "Try alternative analysis framework"
- âŒ "Try again" (NOT a valid backup)
- âŒ "Retry with same approach" (NOT a valid backup)
```

#### Gap 2: Error Propagation Strategies
**Current State**: Binary abort/continue  
**Market Standard**: Three strategies with clear triggers  
**Recommendation**: Expand abort conditions

```markdown
### Error Propagation Strategy

Choose one at workflow start:
1. **halt_on_critical** - Stop immediately on critical failure
2. **continue_and_log** - Proceed with warning, log for review
3. **collaborative_review** - Pause and request human decision (default)
```

#### Gap 3: Verification Before Status Reporting
**Current State**: Status based on intent ("I wrote the fix")  
**Market Standard**: Status based on outcome ("I tested and verified")  
**Recommendation**: Add to proof artifact requirements

```markdown
### Verification Requirement

Before marking any item "Fixed" or "Complete":
- [ ] Automated tests pass (if applicable)
- [ ] Manual verification performed
- [ ] Evidence captured in proof artifact
- [ ] No new warnings or errors introduced
```

#### Gap 4: Criticality Guidance
**Current State**: No guidance on what percentage of steps should be critical  
**Market Standard**: "40-60% should be critical" (Spec_Engine)  
**Recommendation**: Add to `spec.toml` and `dev.toml`

```markdown
### Criticality Balance

When marking steps as critical vs non-critical:
- **Target**: 40-60% of steps should be critical
- **Under-critical (<20%)**: Failures accumulate silently; goal may be unachievable
- **Over-critical (>80%)**: Everything escalates; workflow grinds to halt
- **Exception**: Production deployments may warrant 70%+ critical

Justify each critical flag in your notepad.
```

#### Gap 5: Structured Troubleshooting
**Current State**: `troubleshoot.toml` exists but not connected to other workflows  
**Market Standard**: Spec_Engine's Troubleshooting Cliff reveals need for structured debugging  
**Recommendation**: Add troubleshooting phase to `dev.toml`

```markdown
### If Implementation Fails After 3 Attempts

Switch to structured troubleshooting:
1. Run `troubleshoot.toml` workflow
2. Document all prior attempts in notepad
3. Categorise failure type (config, logic, environment, dependency)
4. Follow troubleshooting phases systematically
5. Do NOT continue ad-hoc debugging
```

---

## Strategic Positioning

### Lia's Differentiation

| Dimension | Market Standard | Lia Approach |
|-----------|-----------------|--------------|
| Speed | Autonomous execution | Guided comprehension |
| Output | Code generated | Knowledge gained |
| Audience | Experienced devs | All developers |
| Philosophy | "AI does the work" | "AI teaches you to work" |
| Transparency | Black box | Glass box |
| Complexity | High (multi-file, CLI) | Low (single TOML) |
| Governance | Heavy (14 Articles) | Light (clear principles) |

### Positioning Statement (Working Draft)

> **Lia**: The educational SDD framework that prioritises understanding over execution.

**Supporting Claims**:
- Transparent, phase-by-phase approach
- Tool-agnostic TOML format
- Learning-focused documentation
- Simple to start, powerful to master

### What This Means Practically

| Keep | Add | Avoid |
|------|-----|-------|
| Tool-agnostic TOML format | Alternative reasoning backups | Matching Spec Kit's autonomous execution |
| Transparent, phase-by-phase approach | Error propagation strategies | Three-file architecture complexity |
| Educational focus | Verification before status | Rigid governance rules |
| Simple start | Criticality guidance | Over-engineering |
| MCP server | Troubleshooting integration | Multi-agent orchestration |

---

## Implementation Roadmap

### P0: Foundation (Immediate - 1 Week)

| Action | Source | Effort | Status |
|--------|--------|--------|--------|
| Add `constitution.toml` | Spec Kit | 4h | âœ… Done |
| Add `recon.toml` | Internal research | 4h | âœ… Done |
| Add scope guard pattern | Vibe Check | 2h | âœ… Done |
| Add context markers to specs | Liatrio SDD | 2h | âœ… Done |
| Add proof artifacts to `dev.toml` | Liatrio SDD | 3h | âœ… Done |
| Add brownfield support to `spec.toml` | OpenSpec | 2h | âœ… Done |

### P1: Differentiation (This Month - 2 Weeks)

| Action | Source | Effort | Status |
|--------|--------|--------|--------|
| Add alternative reasoning backup pattern | Spec_Engine | 3h | ğŸ”² TODO |
| Add error propagation strategies | Spec_Engine | 4h | ğŸ”² TODO |
| Add verification before status requirement | Spec_Engine weakness | 2h | ğŸ”² TODO |
| Add criticality guidance | Spec_Engine | 1h | ğŸ”² TODO |
| Add troubleshooting integration to `dev.toml` | Spec_Engine weakness | 3h | ğŸ”² TODO |
| Create `security.toml` spec | CodeGuard | 4h | ğŸ”² TODO |
| Update README with positioning | Strategic | 2h | ğŸ”² TODO |

### P2: Enhancement (Next Quarter)

| Action | Source | Effort | Status |
|--------|--------|--------|--------|
| Lightweight progress viewer | Market trend | 12h | ğŸ”² Backlog |
| Enhanced MCP server (workflow state as resources) | MCP ecosystem | 8h | ğŸ”² Backlog |
| VSCode extension (basic) | Market trend | 20h | ğŸ”² Backlog |
| Pre-flight validation checklist | Spec_Engine | 6h | ğŸ”² Backlog |
| Multi-format export (Cursor, Claude Code) | APM | 12h | ğŸ”² Backlog |

### Defer (Not Now)

| Action | Rationale |
|--------|-----------|
| Support 15+ AI tools natively | Universal format is enough |
| Full dashboard | Beyond current scope |
| Multi-agent orchestration | Not our differentiation |
| Autonomous execution mode | Contradicts positioning |
| Three-file architecture | Complexity without benefit |

---

## Appendix A: Research Sources

| Source | Stars | Category | URL |
|--------|-------|----------|-----|
| GitHub Spec Kit | 59,000+ | Tier 0 | github.com/github/spec-kit |
| Claude-Flow | 11,000+ | Tier 1 | github.com/ruvnet/claude-flow |
| OpenSpec | 14,800+ | Tier 1 | github.com/openspec/openspec |
| APM | 1,600+ | Tier 2 | github.com/sdi2200262/agentic-project-management |
| Vibe Check MCP | 440+ | Tier 2 | github.com/PV-Bhat/vibe-check-mcp-server |
| Project CodeGuard | 358 | Tier 2 | github.com/project-codeguard/rules |
| Spec Kitty | 282 | Tier 3 | github.com/Priivacy-ai/spec-kitty |
| Clavix | 250 | Tier 3 | github.com/ClavixDev/Clavix |
| Liatrio SDD | 49 | Tier 3 | github.com/liatrio-labs/spec-driven-workflow |
| Spec_Engine | New | Experimental | github.com/earlyprototype/Spec_Engine |

---

## Appendix B: Key Quotes

> "Specifications don't serve codeâ€”code serves specifications."  
> â€” GitHub Spec Kit

> "LLMs can confidently follow flawed plans. Without an external nudge they may spiral into overengineering or misalignment."  
> â€” Vibe Check MCP

> "Brownfield-first: works great beyond 0â†’1"  
> â€” OpenSpec

> "Context rot doesn't announce itself with errors. It creeps in silently."  
> â€” Liatrio SDD

> "If you find yourself typing the same prompt repeatedly, create a Skill."  
> â€” Anthropic Skills

> "Backups MUST be alternative reasoning paths or methods, NOT simple retries."  
> â€” Spec_Engine Article VII

> "The most critical weakness is the lack of a structured framework for post-execution debugging."  
> â€” Spec_Engine Weakness Analysis

---

## Appendix C: Spec_Engine 14 Articles Summary

| Article | Title | Core Requirement |
|---------|-------|------------------|
| I | The North Star Principle | Exactly ONE goal per spec |
| II | Hierarchical Structure | Goal â†’ SPEClet â†’ Task â†’ Step â†’ Backup |
| III | Dual-File Mandate | Markdown + TOML in sync |
| IV | Validation Before Execution | 10-step pre-flight check |
| V | Explicitness Over Implicitness | No vague declarations |
| VI | Critical Flag Discipline | 40-60% steps should be critical |
| VII | Backup Methods | Alternative reasoning, not retries |
| VIII | Error Propagation | Three strategies with clear triggers |
| IX-XIV | (Additional governance) | Various operational rules |

---

*Master synthesis completed: January 2026*  
*Sources: landscape-scan-jan-2026.md, deep-research-jan-2026.md, strategic-synthesis-jan-2026.md, actionable-insights.md, Spec_Engine analysis*
